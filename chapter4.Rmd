---
title: "chapter3"
author: "RK"
date: "13 November 2018"
output: html_document
---

## Chapter 3

This week, I downloaded the MASS library, and with it, the Boston dataset.

It seems like the Boston dataset has 506 rows and 14 columns.

```{r, message = FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(corrplot)
library(MASS)
data("Boston")
str(Boston)
dim(Boston)

```

The Boston data describes housing values in the suburbs of Boston. The columns in the data are:

`crim` per capita crime rate by town.
`zn` proportion of residential land zoned for lots over 25,000 sq.ft.
`indus` proportion of non-retail business acres per town.
`chas` Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
`nox` nitrogen oxides concentration (parts per 10 million).
`rm` average number of rooms per dwelling.
`age` proportion of owner-occupied units built prior to 1940.
`dis` weighted mean of distances to five Boston employment centres.
`rad` index of accessibility to radial highways.
`tax` full-value property-tax rate per \$10,000.
`ptratio` pupil-teacher ratio by town.
`black`1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.
`lstat` lower status of the population (percent).
`medv` median value of owner-occupied homes in \$1000s.



Let's explore the data graphically with a correlation matrix.

```{r, echo=FALSE}

# calculate the correlation matrix and round it
cor_matrix<-cor(Boston) %>% round(digits = 2)

# print the correlation matrix
cor_matrix

# visualize the correlation matrix
corrplot(cor_matrix, method="circle", type="upper", cl.pos="b", tl.pos="d", tl.cex = 0.6)

```



In a corrplot (above), positive correlations are displayed in blue and negative correlations in red color. Color intensity and circle size are proportional to the correlation coefficients.

Therefore, I'll keep an eye out for large dark blue & red circles.

`rad` and `tax` correlate positively (highway accessibility correlates with high tax rate)
`lstat` (lower status) correlates negatively with `medv` (median value of owner-occupied homes)
etc.

However, the variables are in different scales. Clustering methods take the assumption that scales are standardized, so let's standardize the data ((xyz - mean(xyz))/sd(xyz).

```{r, echo=FALSE, message=FALSE}
# center and standardize variables
boston_scaled <- scale(Boston)

# change the object to data frame
boston_scaled <- as.data.frame(boston_scaled)

# summaries of the scaled variables
summary(boston_scaled)

# class of the boston_scaled object
class(boston_scaled)

# create a quantile vector of crim and print it
bins <- quantile(boston_scaled$crim)
bins

# create a categorical variable 'crime'
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))

# look at the table of the new factor crime
table(crime)

# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)

# number of rows in the Boston dataset 
n <- nrow(boston_scaled)

# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)

# create train set
train <- boston_scaled[ind,]

# create test set 
test <- boston_scaled[-ind,]

# save the correct classes from test data
correct_classes <- test$crime

# remove the crime variable from test data
test <- dplyr::select(test, -crime)


```
As we notice, the variables are now on a comparable scale.

I also created a categorical variable of the crime rate in the Boston datasetand dropped the old crime rate variable from the dataset. This is necessary for the clustering we will do later on (as clustering requires a categorigal target variable).

Moreover, I finally divided the dataset to train and test sets. Now 80% of the data belongs to the train set and 20% to the test set.

Now I will fit the Linear Discriminant Analysis to the train data, by using `crime` as a target variable and all other variables as predictors.

```{r, echo=FALSE}
# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)

# print the lda.fit object
lda.fit

# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# plot the lda results
plot <- plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)

```

Predict test data with trained model.

```{r, echo=FALSE}
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)

```

Reload data and rescale:

```{r, echo=FALSE}
data("Boston")
# center and standardize variables
boston_scaled2 <- scale(Boston)

# summaries of the scaled variables
summary(boston_scaled2)

# class of the boston_scaled object
class(boston_scaled2)

```

Now count euclidean and manhattan distances.

```{r, echo=FALSE}
# euclidean distance matrix
dist_eu <- dist(boston_scaled2)

# look at the summary of the distances
summary(dist_eu)

# manhattan distance matrix
dist_man <- dist(boston_scaled2, method = 'manhattan')

# look at the summary of the distances
summary(dist_man)

```

Very interesting distances. Same samish.

Now k-means:

```{r, echo=FALSE}
# k-means clustering
km <-kmeans(boston_scaled2, centers = 3)

# plot the Boston dataset with clusters
pairs(boston_scaled2, col = km$cluster)

set.seed(123)

# determine the number of clusters
k_max <- 10

# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(boston_scaled2, k)$tot.withinss})

# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')

# k-means clustering
km <-kmeans(boston_scaled2, centers = 2)

# plot the Boston dataset with clusters
pairs(boston_scaled2, col = km$cluster)

```